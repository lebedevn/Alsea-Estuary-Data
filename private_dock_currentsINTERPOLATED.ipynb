{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76472b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# private dock midestuary\n",
    "# Data points every 5 minuetes\n",
    "# HDR is sea level\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import re\n",
    "import json\n",
    "%matplotlib ipympl\n",
    "\n",
    "def Array_To_DataFrame(matDF, varName) :\n",
    "    npArray = np.array([])\n",
    "    for i in range (matDF[varName].shape[0]) :\n",
    "        npArray = np.concatenate((npArray, matDF[varName][i].flatten()))\n",
    "    return npArray\n",
    "def matFile_To_DF(matFile) :\n",
    "    tempDF = sio.loadmat(matFile)\n",
    "    matDataMidFiltered = {}\n",
    "    for dictKey in tempDF.keys() :\n",
    "        if isinstance(tempDF[dictKey], np.ndarray) :\n",
    "            if tempDF[dictKey].shape[0] > 1 :\n",
    "                matDataMidFiltered.update({dictKey : tempDF[dictKey]})\n",
    "\n",
    "    matMidDF = pd.DataFrame({dictKey: np.array(dictValue).flatten() for dictKey, dictValue in matDataMidFiltered.items()})\n",
    "    return matMidDF\n",
    "\n",
    "def matFileCurrent_To_DF(matFile) :\n",
    "    tempDF = sio.loadmat(matFile)\n",
    "    matDataMidFiltered = {}\n",
    "    for dictKey in tempDF.keys() :\n",
    "        if isinstance(tempDF[dictKey], np.ndarray) :\n",
    "            if tempDF[dictKey].shape[0] > 1 and tempDF[dictKey].shape[1] > 1 :\n",
    "                for i in range(tempDF[dictKey].shape[0]) :\n",
    "                    matDataMidFiltered.update({dictKey + '_z_' + str(i) : tempDF[dictKey][i]})\n",
    "            elif dictKey == 'DN':\n",
    "                matDataMidFiltered.update({dictKey : tempDF[dictKey]})\n",
    "\n",
    "    matMidDF = pd.DataFrame({dictKey: np.array(dictValue).flatten() for dictKey, dictValue in matDataMidFiltered.items()})\n",
    "    matMidZ = pd.DataFrame({'z' : tempDF['Z'].flatten()})\n",
    "    return (matMidDF, matMidZ, tempDF)\n",
    "\n",
    "# import files for 2012-2013 and extract sea level data\n",
    "matDockDF = matFile_To_DF('2013_14\\\\P_processed_01.mat')\n",
    "# import downriver current data\n",
    "mainFile = sio.loadmat('UV_SSC_extrap_rotatecurrents.mat')\n",
    "\n",
    "DN1314 = mainFile['DN1314']\n",
    "alongChannelVelocityDR = mainFile['UsiR_DR1314']\n",
    "alongChannelVelocityUR = mainFile['UsiR_UR1314']\n",
    "depthsDR = mainFile['ZsiDR1314']\n",
    "depthsUR = mainFile['ZsiUR1314']\n",
    "seaLevelDR = mainFile['HlDR']\n",
    "seaLevelUR = mainFile['HlUR']\n",
    "\n",
    "# create depth range for the buckets splits depths into 20 equal intervals\n",
    "depthRangeDR = np.linspace(depthsDR.min(), depthsDR.max(), num=depthsDR.shape[0] + 1)\n",
    "depthBucketsDR = []\n",
    "# create array with nans to hold same length of the original velocity array\n",
    "bucketAlongChannelVelocityDR = np.full(alongChannelVelocityDR.shape, np.nan)\n",
    "# array to count number of velocity arrays in each bucket\n",
    "bucketVelocityCountDR = np.full(alongChannelVelocityDR.shape, 0)\n",
    "\n",
    "# loop through each depth range and place velocities in buckets\n",
    "for i in range(depthRangeDR.shape[0]-1) :\n",
    "    # mean depth for each bucket\n",
    "    depthBucketsDR.append((depthRangeDR[i] + depthRangeDR[i+1])/2)\n",
    "    # go through time values in the along channel velocity array\n",
    "    for j in range(alongChannelVelocityDR.shape[1]) :\n",
    "        # go through depth values to find which bucket\n",
    "        for k in range(alongChannelVelocityDR.shape[0]) :\n",
    "            # if depth at that point is in the current bucket range add to bucket\n",
    "            if depthsDR[k][j] >= depthRangeDR[i] and depthsDR[k][j] < depthRangeDR[i+1] :\n",
    "                # if value is nan, gives it the along channel velocity value\n",
    "                if np.isnan(bucketAlongChannelVelocityDR[i][j]) :\n",
    "                    bucketAlongChannelVelocityDR[i][j] = alongChannelVelocityDR[k][j]\n",
    "                    bucketVelocityCountDR[i][j] = 1\n",
    "                # if value is not nan, adds to existing value\n",
    "                else :\n",
    "                    bucketAlongChannelVelocityDR[i][j] = bucketAlongChannelVelocityDR[i][j] + np.nan_to_num(alongChannelVelocityDR[k][j])\n",
    "                    bucketVelocityCountDR[i][j] += 1\n",
    "# divide by number of values in each bucket to get mean\n",
    "for i in range(bucketAlongChannelVelocityDR.shape[0]) :\n",
    "    for j in range(bucketAlongChannelVelocityDR.shape[1]) :\n",
    "        if bucketVelocityCountDR[i,j] > 0 :\n",
    "            bucketAlongChannelVelocityDR[i,j] = bucketAlongChannelVelocityDR[i,j] / bucketVelocityCountDR[i,j]\n",
    "\n",
    "seaLevel = mainFile['HlDR']\n",
    "ADCPDict = {'DN' : DN1314.flatten(), 'U' : bucketAlongChannelVelocityDR, 'Z' : depthBucketsDR + abs(depthRangeDR[0]), 'H' : seaLevel.flatten()}\n",
    "# resize U array to match matDockDF DN length\n",
    "ADCPDictUResized = np.resize(ADCPDict['U'], (ADCPDict['U'].shape[0], 38311))\n",
    "\n",
    "for i in range(ADCPDict['U'].shape[0]) :\n",
    "    # interpolate each depth level to match matDockDF DN values\n",
    "    tempNp = np.interp(matDockDF['DN'], ADCPDict['DN'].flatten(), ADCPDict['U'][i])\n",
    "    ADCPDictUResized[i] = tempNp\n",
    "#mat lab date origin\n",
    "origin = np.datetime64('0000-01-01', 'D') - np.timedelta64(1, 'D')\n",
    "#convert DN to datetime\n",
    "matDockDF['DN'] = (matDockDF['DN'] * np.timedelta64(24*3600000, 'ms') + origin + np.timedelta64(500, 'ms')).astype('datetime64[s]')\n",
    "ADCPDict['DN'] = (ADCPDict['DN'] * np.timedelta64(24*3600000, 'ms') + origin + np.timedelta64(500, 'ms')).astype('datetime64[s]')\n",
    "\n",
    "# CALCULATION OF DEPTH AVERAGED VELOCITY FOR DOWNRIVER SITE du/dz\n",
    "downriverDepthAveragedVelocity = np.full(ADCPDictUResized.shape[1], np.nan)\n",
    "for j in range(ADCPDictUResized.shape[1]) :\n",
    "    downriverDepthAveragedVelocity[j] = np.nanmean(ADCPDictUResized[:,j])\n",
    "ADCPDict['DepthAveragedU13_14'] = downriverDepthAveragedVelocity    \n",
    "\n",
    "# UPRIVER\n",
    "\n",
    "# create depth range for the buckets splits depths into 20 equal intervals\n",
    "depthRangeUR = np.linspace(depthsUR.min(), depthsUR.max(), num=depthsUR.shape[0] + 1)\n",
    "depthBucketsUR = []\n",
    "# create array with nans to hold same length of the original velocity array\n",
    "bucketAlongChannelVelocityUR = np.full(alongChannelVelocityUR.shape, np.nan)\n",
    "# array to count number of velocity arrays in each bucket\n",
    "bucketVelocityCountUR = np.full(alongChannelVelocityUR.shape, 0)\n",
    "\n",
    "# loop through each depth range and place velocities in buckets\n",
    "for i in range(depthRangeUR.shape[0]-1) :\n",
    "    # mean depth for each bucket\n",
    "    depthBucketsUR.append((depthRangeUR[i] + depthRangeUR[i+1])/2)\n",
    "    # go through time values in the along channel velocity array\n",
    "    for j in range(alongChannelVelocityUR.shape[1]) :\n",
    "        # go through depth values to find which bucket\n",
    "        for k in range(alongChannelVelocityUR.shape[0]) :\n",
    "            # if depth at that point is in the current bucket range add to bucket\n",
    "            if depthsUR[k][j] >= depthRangeUR[i] and depthsDR[k][j] < depthRangeUR[i+1] :\n",
    "                # if value is nan, gives it the along channel velocity value\n",
    "                if np.isnan(bucketAlongChannelVelocityUR[i][j]) :\n",
    "                    bucketAlongChannelVelocityUR[i][j] = alongChannelVelocityUR[k][j]\n",
    "                    bucketVelocityCountUR[i][j] = 1\n",
    "                # if value is not nan, adds to existing value\n",
    "                else :\n",
    "                    bucketAlongChannelVelocityUR[i][j] = bucketAlongChannelVelocityUR[i][j] + np.nan_to_num(alongChannelVelocityUR[k][j])\n",
    "                    bucketVelocityCountUR[i][j] += 1\n",
    "# divide by number of values in each bucket to get mean\n",
    "for i in range(bucketAlongChannelVelocityUR.shape[0]) :\n",
    "    for j in range(bucketAlongChannelVelocityUR.shape[1]) :\n",
    "        if bucketVelocityCountUR[i,j] > 0 :\n",
    "            bucketAlongChannelVelocityUR[i,j] = bucketAlongChannelVelocityUR[i,j] / bucketVelocityCountUR[i,j]\n",
    "\n",
    "seaLevel = mainFile['HlDR']\n",
    "ADCPDict = {'DN' : DN1314.flatten(), 'U' : bucketAlongChannelVelocityDR, 'Z' : depthBucketsDR + abs(depthRangeDR[0]), 'H' : seaLevel.flatten()}\n",
    "AquadoppDict = {'DN' : DN1314.flatten(), 'U' : bucketAlongChannelVelocityUR, 'Z' : depthBucketsUR + abs(depthRangeUR[0]), 'H' : seaLevel.flatten()}\n",
    "# resize U array to match matDockDF DN length\n",
    "ADCPDictUResized = np.resize(ADCPDict['U'], (ADCPDict['U'].shape[0], 38311))\n",
    "AquadoppDictUResized = np.resize(AquadoppDict['U'], (AquadoppDict['U'].shape[0], 38311))\n",
    "\n",
    "for i in range(ADCPDict['U'].shape[0]) :\n",
    "    # interpolate each depth level to match matDockDF DN values\n",
    "    tempNp = np.interp(matDockDF['DN'], ADCPDict['DN'].flatten(), ADCPDict['U'][i])\n",
    "    ADCPDictUResized[i] = tempNp\n",
    "for i in range(AquadoppDict['U'].shape[0]) :\n",
    "    # interpolate each depth level to match matDockDF DN values\n",
    "    tempNp = np.interp(matDockDF['DN'], AquadoppDict['DN'].flatten(), AquadoppDict['U'][i])\n",
    "    AquadoppDictUResized[i] = tempNp\n",
    "#mat lab date origin\n",
    "origin = np.datetime64('0000-01-01', 'D') - np.timedelta64(1, 'D')\n",
    "#convert DN to datetime\n",
    "matDockDF['DN'] = (matDockDF['DN'] * np.timedelta64(24*3600000, 'ms') + origin + np.timedelta64(500, 'ms')).astype('datetime64[s]')\n",
    "ADCPDict['DN'] = (ADCPDict['DN'] * np.timedelta64(24*3600000, 'ms') + origin + np.timedelta64(500, 'ms')).astype('datetime64[s]')\n",
    "AquadoppDict['DN'] = (AquadoppDict['DN'] * np.timedelta64(24*3600000, 'ms') + origin + np.timedelta64(500, 'ms')).astype('datetime64[s]')\n",
    "\n",
    "# CALCULATION OF DEPTH AVERAGED VELOCITY FOR DOWNRIVER SITE du/dz\n",
    "downriverDepthAveragedVelocity = np.full(ADCPDictUResized.shape[1], np.nan)\n",
    "for j in range(ADCPDictUResized.shape[1]) :\n",
    "    downriverDepthAveragedVelocity[j] = np.nanmean(ADCPDictUResized[:,j])\n",
    "ADCPDict['DepthAveragedU13_14'] = downriverDepthAveragedVelocity    \n",
    "# CALCULATION OF DEPTH AVERAGED VELOCITY FOR UPRIVER SITE du/dz\n",
    "upriverDepthAveragedVelocity = np.full(AquadoppDictUResized.shape[1], np.nan)\n",
    "for j in range(AquadoppDictUResized.shape[1]) :\n",
    "    upriverDepthAveragedVelocity[j] = np.nanmean(AquadoppDictUResized[:,j])\n",
    "AquadoppDict['DepthAveragedU13_14'] = upriverDepthAveragedVelocity\n",
    "\n",
    "depthAvgfig = px.line(x = matDockDF['DN'], y = [ADCPDict['DepthAveragedU13_14']], color_discrete_sequence= [\"black\"], title = \"Depth Averaged Velocity Downriver 2013-2014\")\n",
    "depthAvgFigLabel = ['Downriver Depth Averaged Velocity']\n",
    "for idx in range(len(depthAvgFigLabel)):\n",
    "    depthAvgfig.data[idx].name = depthAvgFigLabel[idx]\n",
    "    depthAvgfig.data[idx].hovertemplate = 'variable=' + depthAvgFigLabel[idx] + '<br>x=%{x}<br>value=%{y}<extra></extra>'\n",
    "    depthAvgfig.data[idx].legendgroup = depthAvgFigLabel[idx]\n",
    "\n",
    "\n",
    "depthAvgfig.update_layout(title=dict(text= \"Depth Averaged Velocity for 2013-2014\", font=dict(size=25)))\n",
    "depthAvgfig.update_xaxes(tickangle=30)\n",
    "depthAvgfig.update_xaxes(rangeslider_visible=True)\n",
    "depthAvgfig.update_xaxes(range = [pd.Timestamp('2013-10-28'),pd.Timestamp('2014-03-17')])\n",
    "depthAvgfig.update_layout(xaxis_title=\"Date\", yaxis_title=\"Depth Averaged Velocity (m/s)\", legend_title=\"Locations\")\n",
    "depthAvgfig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 8))\n",
    "plt.subplots_adjust(hspace=3)\n",
    "contourPlot = ax1.contourf(matDockDF['DN'], (ADCPDict['Z']), ADCPDictUResized, levels = len(ADCPDict['Z']), cmap = 'cividis')\n",
    "fig.colorbar(contourPlot, ax = ax1, label = 'Along Channel Velocity (m/s)')\n",
    "ax1.plot(matDockDF['DN'], matDockDF['Hdr'], linewidth=2, label='SeaLevel at Downriver Location', color = 'black')\n",
    "ax1.set_title('Sea Level at Downriver Location and Current Profile 2013-2014')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Depth (m)')\n",
    "ax1.set_xlim([matDockDF['DN'].min(), matDockDF['DN'].max()])\n",
    "ax1.tick_params('x', rotation = -30)\n",
    "\n",
    "contourPlot2 = ax2.contourf(matDockDF['DN'], (AquadoppDict['Z']), AquadoppDictUResized, levels = len(AquaddoppDict['Z']), cmap = 'cividis')\n",
    "fig.colorbar(contourPlot2, ax = ax2, label = 'Along Channel Velocity (m/s)')\n",
    "ax2.plot(matDockDF['DN'], matDockDF['Hur'], linewidth=2, label='SeaLevel at Upriver Location', color = 'black')\n",
    "ax2.set_title('Sea Level at Upriver Location and Current Profile 2013-2014')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Depth (m)')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ace70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
